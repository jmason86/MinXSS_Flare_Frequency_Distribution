{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io.idl import readsav\n",
    "import astropy.units as u\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "#mpl.use('macosx')\n",
    "#sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating away the MinXSS data denominators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now define some functions to handle integrating across the MinXSS science data energy and time. MinXSS-1 data data are in photons / s / cm2 / keV. These first two functions will remove the /keV and /s, respectively. Then we create a function to account for the fact that we took these measurements at 1 AU, which gets rid of the /cm2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_spectrum_energy(spectral_irradiance, energy):\n",
    "    irradiance_masked = np.ma.array(spectral_irradiance, mask=np.isnan(spectral_irradiance))  # Causes the units to get dropped\n",
    "    return np.trapz(irradiance_masked, energy)\n",
    "\n",
    "\n",
    "def integrate_spectrum_time(irradiance, time_jd):\n",
    "    #irradiance_masked = np.ma.array(irradiance, mask=np.isnan(irradiance))  # Do I need this since the mask was already done in the energy integration? Don't want it because it drops the astropy units\n",
    "    time_seconds = (time_jd - time_jd[0]) * 86400 * u.second\n",
    "    return np.trapz(irradiance, time_seconds)\n",
    "\n",
    "\n",
    "def integrate_photon_flux_1au(fluxes):\n",
    "    return [flux * 4 * np.pi * ((1*u.AU).to(u.cm))**2 for flux in fluxes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other handy functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function that'll just fit a slope over whatever data you pass it, and plot over the most recent plot. We also restrict the xrange that the fit is applied to, and provide some default parameters for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_slope(x, y, xmin=2e30, xmax=1e32):\n",
    "    mask = (x >= xmin) & (x <= xmax)\n",
    "    logx = np.log10(x[mask])\n",
    "    logy = np.log10(y[mask])\n",
    "    p = np.polyfit(logx, logy, deg=1)\n",
    "    xfit = np.logspace(np.floor(np.log10(xmin)), np.floor(np.log10(xmax)), num=30)\n",
    "    line = 10**p[1] * xfit ** p[0]\n",
    "    plt.plot(xfit, line)\n",
    "    plt.title('$\\\\alpha$ = {0:.2f}'.format(p[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have a convenience function for extracting the julian date from the MinXSS data product, since it's kind of an ugly accessor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_jd(minxsslevel1):\n",
    "    return np.array([minxsslevel1['time'][i]['jd'][0] for i in range(len(minxsslevel1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/jmason86/Dropbox/minxss_dropbox/data/fm1/level1/'\n",
    "data = readsav('{}minxss1_l1_mission_length_v2.sav'.format(data_path))\n",
    "minxsslevel1 = data.minxsslevel1.x123[0].copy()\n",
    "\n",
    "goes_events_path = '/Users/jmason86/Dropbox/Research/Data/GOES/events/'\n",
    "data_goes = readsav('{}GOES_events_MinXSS1_era.sav'.format(goes_events_path))\n",
    "goes_events = data_goes.goesevents.copy()\n",
    "goes_start_jd = goes_events['eventstarttimejd']\n",
    "goes_end_jd = goes_start_jd + 1/24  # Nearly all flares are << 1 hour. The post-flare time intensity is much smaller and will add little to the time-integrated value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of dN/dE per year vs energy [erg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate spectra across energy to produce one value per time\n",
    "spectral_irradiance = np.stack(minxsslevel1['irradiance']) * (u.photon / u.second / u.centimeter**2 / u.keV)\n",
    "energy = minxsslevel1[0]['energy']\n",
    "irradiance = integrate_spectrum_energy(spectral_irradiance, energy) * (u.photon / u.second / u.centimeter**2)\n",
    "\n",
    "# Integrate across the times of all flares\n",
    "time_jd = extract_time_jd(minxsslevel1)\n",
    "# Loop through all the flares identified by GOES\n",
    "photon_fluxes = []\n",
    "for i in range(len(goes_start_jd)):\n",
    "    flare_time_indices = np.where((time_jd >= goes_start_jd[i]) & (time_jd <= goes_end_jd[i]))\n",
    "    if flare_time_indices[0].size > 1:\n",
    "        photon_fluxes.append(integrate_spectrum_time(irradiance[flare_time_indices], time_jd[flare_time_indices]))\n",
    "\n",
    "# Now integrate that over 1 AU to get rid of the / cm^2\n",
    "photons = integrate_photon_flux_1au(photon_fluxes)\n",
    "\n",
    "# Convert energy units from keV to erg\n",
    "energy = u.keV.to(u.erg, energy) * u.erg\n",
    "\n",
    "# Convert photons to energy\n",
    "mean_energy = np.ma.array(energy, mask=(energy < 0)).mean() / u.photon\n",
    "measured_energy = [photon * mean_energy for photon in photons]\n",
    "\n",
    "# Prepare for histograms\n",
    "m_e = np.array([m.value for m in measured_energy])\n",
    "log_bins = np.geomspace(m_e.min(), m_e.max(), 30)\n",
    "bin_centers = np.sqrt(log_bins[1:] * log_bins[:-1])\n",
    "\n",
    "# Count number of flares in each bin: N\n",
    "hist = np.histogram(m_e, bins=log_bins)\n",
    "n = hist[0]\n",
    "\n",
    "# Divide N by energy of its corresponding bin\n",
    "dn_de = n / bin_centers\n",
    "\n",
    "# Divide all bins by the duration of observations in years\n",
    "observation_duration_years = (minxsslevel1['time'][-1]['jd'] - minxsslevel1['time'][0]['jd']) / 365.25\n",
    "dn_de_per_year = dn_de / observation_duration_years\n",
    "\n",
    "plt.figure()\n",
    "plt.step(bin_centers, dn_de_per_year)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SXR Solar Flare Energy [erg]')\n",
    "plt.ylabel('dN/dE per year')\n",
    "\n",
    "fit_slope(bin_centers, dn_de_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
